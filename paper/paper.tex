% \documentclass[sigplan, screen]{acmart}
% \documentclass[sigplan, screen, anonymous, review, authordraft]{acmart}
% \documentclass[sigplan,10pt,anonymous,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
\documentclass[sigplan,10pt, anonymous]{acmart}

\usepackage{agda-unicode}
\usepackage{agda-generated}
\AgdaNoSpaceAroundCode{}

\bibliographystyle{ACM-Reference-Format}

\title{Abstractions for Multi-Sorted Substitutions}

\author{Hannes Saffrich}
\orcid{0000-0002-1825-0097}                 %% \orcid is optional
\affiliation{
  % \department{Department1}                %% \department is recommended
  \institution{University of Freiburg}      %% \institution is required
  \country{Germany}                         %% \country is recommended
}
\email{saffrich@informatik.uni-freiburg.de} %% \email is recommended

% \author{Peter Thiemann}
% \orcid{0000-0002-9000-1239}                 %% \orcid is optional
% \affiliation{
%   % \department{Department2a}               %% \department is recommended
%   \institution{University of Freiburg}      %% \institution is required
%   \country{Germany}                         %% \country is recommended
% }
% \email{thiemann@informatik.uni-freiburg.de} %% \email is recommended

\usepackage{tcolorbox}

\newenvironment{LibCode*}{%
  \begin{tcolorbox}[%
    colframe=white,%
    boxrule=0.0pt,%
    top=2.5pt,%
    left=2.5pt,%
    bottom=2.5pt,%
    right=2.5pt,%
    boxsep=0pt%
  ]\vspace{-0.2\baselineskip}%
}{%
  \vspace{-1\baselineskip}%
  \end{tcolorbox}%
}

\newenvironment{ExampleCode*}{%
  \begin{tcolorbox}[%
    colframe=white,%
    colback=yellow!5,%
    boxrule=0.0pt,%
    top=2.5pt,%
    left=2.5pt,%
    bottom=2.5pt,%
    right=2.5pt,%
    boxsep=0pt%
  ]\vspace{-0.2\baselineskip}%
}{%
  \vspace{-1\baselineskip}%
  \end{tcolorbox}%
}

\newcommand*\LibCode[1]{\begin{LibCode*}{#1}\end{LibCode*}}
\newcommand*\AppCode[1]{{#1}}
\newcommand*\ExampleCode[1]{\begin{ExampleCode*}{#1}\end{ExampleCode*}}

% \setlength\fboxsep{0pt}
% \usepackage{realboxes}
% \definecolor{mygray}{rgb}{0.95,0.95,0.95}
% \newcommand*\ACode[1]{\Colorbox{mygray}{\AgdaFontStyle{#1}}}

% \newcommand*\ACode[1]{\AgdaFontStyle{#1}}

% \newcommand*\ACode[1]{\texttt{#1}}

\definecolor{mygray}{rgb}{0.4,0.4,0.4}
\newcommand*\ACode[1]{\AgdaFontStyle{\textcolor{mygray}{#1}}}

\newcommand*\AField[1]{\AgdaField{#1}}
\newcommand*\ACon[1]{\AgdaInductiveConstructor{#1}}
\newcommand*\AKw[1]{\AgdaKeyword{#1}}
\newcommand*\ADef[1]{\AgdaFunction{#1}}

\begin{document}

  \begin{abstract}
    Formalizing a typed programming language in a proof assistant
    requires to choose representations for variables and typing.
    Variables are often represented as de Bruijn indices, where
    substitution is usually defined in terms of renamings to allow for
    proofs by structural induction.
    Typing can be represented extrinsically by defining untyped terms and a typing
    relation, or intrinsically by combining syntax and typing into a single
    definition of well-typed terms.
    For extrinsic typing, there is again a choice between extrinsic
    scoping, where terms and the notion of free variables are defined
    separately, and intrinsic scoping, where terms are indexed by their
    free variables.

    This paper describes an Agda framework for formalizing programming
    languages with extrinsic typing, intrinsic scoping, and de Bruijn
    Indices for variables.
    The framework supports object languages with arbitrary many
    variable sorts and dependencies, making it suitable for
    polymorphic languages and dependent types.
    Given an Agda definition of syntax and typing, the framework derives
    substitution operations and lemmas for untyped terms, and provides an
    abstraction to prove type preservation of these operations with
    just a single lemma.
    The key insights behind the framework are the use of multi-sorted syntax
    definitions, which enable parallel substitutions that replace
    all variables of all sorts simultaneously, and
    abstractions that unify the definitions, compositions, and typings
    of multi-sorted renamings and substitutions.
    Case studies have been conducted to prove subject reduction for
    System F with subtyping, dependently typed lambda calculus, and lambda
    calculus with pattern matching.
  \end{abstract}

  \maketitle

  \section{Introduction}
  \label{sec:introduction}

  Formalizing programming languages in proof assistants quickly gets
  repetitive. Almost every programming language supports variables
  with static binding, and hence requires numerous definitions and
  lemmas related to variable substitution.

  Additionally, repetition can also occur within a single formalization.
  This can be seen with polymorphic languages, where multiple sorts
  of variables are present.
  Consider for example System F, which supports both expression- and
  type-variables.
  With a naive approach, the whole substitution machinery needs to be
  duplicated three times! We need to substitute expression-variables in
  expressions, type-variables in types, but we also need to substitute
  type-variables in expressions.
  Even worse, having two substitutions acting on expressions, requires
  to also prove lemmas about their interactions.
  If we would additionally introduce kind-variables, we would end up
  with a total of six duplications of the substition machinery and
  corresponding interaction lemmas!
  
  Further repetition can be introduced by the choice of variable
  representation. For example, for de Bruijn indices, substitution is
  usually defined in terms of renamings to allow for structural
  induction.
  With a naive approach, this would again double the amount of
  substitution machinery, as all definitions and lemmas need to be
  made first for renamings and then again for substitutions.

  Even more repetition is introduced by having a typed language,
  where for each substitution (and renaming) operation, we need to prove
  that the operation preserves typing, again doubling the repetition.

  % In summary, to have enough substitution machinery to prove subject
  % reduction for a language with expression-, type-, and
  % kind-variables one can end up with a total of 24
  % repetitions for each definition related to substitution, not counting
  % the interaction lemmas between different substitutions that are
  % acting on the same syntactic categories!
  In summary, formalizing a language with expression-, type-, and
  kind-variables with a naive approach can end up with a total of 24
  repetitions for each definition related to substitution, not counting
  the interaction lemmas between different substitutions that are
  acting on the same syntactic categories!

  In our framework we address those repetitions as followed:
  \begin{itemize}
  \item
    Instead of requiring a separate substitution for each sort of variable,
    we define a multi-sorted substitution which replaces all variables
    of all sorts simultaneously and can be applied to terms of all syntactic categories.
    This not only unifies many different definitions, removing redundancy on the way,
    but also eliminates the need for interaction lemmas.
  \item
    We use de Bruijn indices, but unify renamings and typings using the Kit abstraction.
    We further developed a Kit-like abstraction to also unify
    compositions of renamings and substitutions.
  \end{itemize}
  
  

  A close examination of the formalizations reveals that variable
  substitution behaves uniformly across languages, in the sense that
  the behavior of substitution is completely determined by the positions
  of variable bindings and variable uses.


  Formalizing a typed programming language in a proof assistant
  requires to choose between an extrinsic and intrinsic representation
  of typing.

  With \emph{intrinsic typing}, the definitions of syntax and typing
  are merged into a single definition of well-typed terms.
  Consequently, the definition of an operation on terms also acts
  as a proof of type preservation for that operation, as it has to
  map well-typed terms to well-typed terms.
  For example, the definition of substitution
  also acts as a proof that substitution preserves typing, and the
  definition of a small-step semantics also acts as a proof for subject
  reduction.
  This often has the benefit of more concise code, as shared structure
  between definitions and preservation lemmas does not need to be
  repeated.

  With \emph{extrinsic typing}, the definitions of syntax and typing
  are kept separately: the syntax is defined first, and then typing is
  defined as a relation. Consequently, operations on terms and
  their type preservation lemmas are also separate entities.
  This has the benefit that specification and proofs are kept strictly separate,
  allowing a human to judge whether a specification is correct without also
  having to understand the proofs.
  % To understand the specification of intrinsic typing one has to
  % additionally understand the proofs, which can introduce significant
  % cognitive overhead.

  For our substition framework, we choose to work with extrinsic
  typing for a different reason.

  % For substitution, this separation brings an opportunity for automation:
  % free from the arbitrary complexity of typing relations,
  % the definitions and lemmas of substitution for untyped terms
  % behaves uniformly across object languages, and can be derived
  % completely.

  % While extrinsic typing cannot eliminate the shared structure between
  % definitions and preservation lemmas, it can automated by reflection
  % or generic programming techniques, leaving only the preservation lemmas
  % to be proven by the programmer. While typing can be arbitrary complex,
  % the definition and metatheory of untyped substitution behaves the same
  % across languages.

  % However, when working with library support, this is less of a benefit.
  % Most operations, like substitution, have a generic definition and
  % metatheory across languages, which can be derived automatically via
  % reflection or generic programming techniques.
  % Only by adding a typing-relation 


  % However, intrinsic typing also has three major drawbacks:
  % \begin{enumerate}
  % \item
  %   It is more difficult to judge whether a specification is correct,
  %   because there is no clear separation between specification and proofs.
  %   To understand the specification one has to additionally
  %   understand the proofs, which can introduce significant cognitive overhead.
  %   % For example specifying a small step semantics is directly intertwined
  %   % with the proof of subject reduction.
  % \item
  %   It is less uniform for object languages with multiple variable
  %   sorts, e.g. type- and expression-variables. In such a scenario,
  %   types are usually indexed by kinds and expressions by kinds and types.
  %   This requires not only a type-in-type and expression-in-expression
  %   substitution, but also a type-in-expression substitution, which causes
  %   interactions between different types of substitutions introducing
  %   additional complexity.
  %   The duplication increases even more if one additionally introduces
  %   kind-variables. Then a total of 6 different substitutions and
  %   their interactions is required.
  %   Unifying these substitutions to reduce repetition is difficult
  %   with intrinsic typing due to the interdependence of definitions.
  % \item
  %   It is less suitable for automation, because type preservation is baked
  %   into the syntax definition and type preservation can become arbitrary complex
  %   depending on the typing relation. This can prevent substitition
  %   definition and lemmas from being derived, where otherwise it would be possible.
  % \end{enumerate}
  % With extrinsic typing the major drawback is the duplication between
  % definitions and type preservation lemmas, which we found more
  % suitable to be eliminated by automation.

  % To combat those drawbacks, we went in the direction of intrinsically
  % scoped syntax in our search for a general, clean, and automated framework
  % for metatheory.

  \subsection{Structure}
  \label{sec:introduction:structure}

  The rest of this paper will introduce our framework using System F
  as a running example for a type soundness proof.

  Code of the framework is displayed in gray boxes.
  Code of examples is written in yellow boxes.
  Code of the System F formalization is written without boxes. The
  latter is the only code a user of our framework has to write.

  In this paper we present a simplified version of the actual
  framework, focusing on the core concepts. We present all necessary
  definitions and lemmas, but omit some proofs for the sake of
  space. The omitted proofs can be found in Appendix~\ref{sec:proofs}
  and in the supplementary material. The full framework can be found at
  TODO.

  The rest of this paper is structured as followed:
  Section~\ref{sec:syntax} introduces the multi-sorted syntax and compares it to the
  more common unsorted syntax.
  Section~\ref{sec:maps} introduces multi-sorted substitutions and renamings, and
  an abstraction to unify them.
  Section~\ref{sec:composition} introduces composition of multi-sorted
  substitions and renamings, and an abstraction to unify all four
  compositions.
  Section~\ref{sec:types} shows how to introduce the notion of types
  for multi-sorted syntax and how to define typing contexts.
  Section~\ref{sec:typing} shows how to define a multi-sorted typing relation,
  and an abstraction to unify type preservattion lemmas for renamings and substitutions.
  Section~\ref{sec:semantics} introduces a small-step operational semantics for System F.
  Section~\ref{sec:subjectreduction} proves the subject reduction lemma for System F.
  Section~\ref{sec:reflection} describes the class of object languages covered by
  our reflection algorithm.
  Section~\ref{sec:casestudies} describes case studies of object languages beyond System F.
  Section~\ref{sec:related} discusses related work.
  Section~\ref{sec:future} describes future work.
  Section~\ref{sec:conclusion} concludes.

  \subsection{Contributions}
  \label{sec:introduction:contributions}
  \begin{enumerate}
  \item
    a novel approach for formalizing intrinsically-scoped syntax with
    multiple variable sorts as a special kind of intrinsically-typed
    syntax, we call \emph{multi-sorted syntax};
  \item
    an adaptation of McBride's kit-abstraction for unifying renamings
    and substitutions to multi-sorted syntax;
  \item
    a novel abstraction for composition and it's metatheory, unifying
    the four compositions between renamings and substitutions;
  \item
    a novel abstraction for typing relations, unifying type
    preservation of renaming and substitution;
  \item
    a formalized specification of a large class of object languages
    for which substitution and lemmas can be derived generically.
  \item
    an implementation of the concepts as framework in Agda featuring
    a reflection algorithm, representation independence for
    substitutions and typing contexts, heterogeneous equality between
    renamings and substitutions, and free of postulated axioms.
  \item
    three case studies using our approach to prove subject reduction
    for System~F with subtyping, a dependently-typed lambda calculus, and
    pattern matching.
  \end{enumerate}

  \section{Syntax}
  \label{sec:syntax}
  \subsection{Unsorted Syntax}
  \label{sec:syntax:single}
  The following shows a typical intrinsically-scoped syntax of System F:
  \ExampleCode\FUnsortedSyntax

  \ACode{\ACon{Type}}s are indexed by the number of free type
  variables \ACode{n}.
  \ACode{\ACon{Expr}}essions are additionally indexed by the number of
  free expression variables \ACode{m}.
  Variables \ACode{\ACon{`\_}} are represented as DeBruijn-indices, where
  \ACode{\ACon{Fin} n} is the type of \ACode{n} elements.

  We identify two drawbacks with this style of syntax:
  \begin{enumerate}
  \item
    the syntactic categories (\ACode{\ACon{Kind}},
    \ACode{\ACon{Type}}, and \ACode{\ACon{Expr}})
    have different types, which makes it difficult to treat them uniformly; and
  \item the different sorts of variables are modeled separately, which requires to define not just
    type-in-type and expression-in-expression substitution, but also type-in-expression substitution.
    Consequently, interaction lemmas between those substitutions are required.
    In general, this leads to a combinatory explosion of
    substitutions, e.g.\ adding kind variables would lead to a total of 6
    different substitutions and corresponding interaction lemmas.
  \end{enumerate}
  To avoid these drawbacks, we instead use a multi-sorted syntax.

  \subsection{Multi-Sorted Syntax}
  \label{sec:syntax:multi}
  A multi-sorted syntax is defined by a single type of sort-indexed terms.

  A sort describes to which syntactic category a term belongs and is
  itself indexed by a sort type, which describes whether the syntax
  permits variables of this sort:
  \LibCode\KSortTy
  \AppCode\FSort
  
  The term type \ACode{S \ACon{⊢} s} is then indexed by its sort
  \ACode{s} and the sorts of its free variables \ACode{S}.
  For example, \ACode{\ACon{[𝕥, 𝕥] ⊢ 𝕖}} is the type of expressions
  (\ACode{\ACon{𝕖}}) with two free type-variables (\ACode{\ACon{𝕥}}).
  \AppCode\FSyntax
  The notation \ACode{\ACon{\_⊢\_}} is often used for terms in
  intrinsically-typed languages. This is no accident: in effect, we
  defined an intrinsically-typed language with the twist that the
  typing relation assures exactly that the syntactic categories are followed.
  Sorts \ACode{s} correspond to types, and lists of sorts \ACode{S}
  correspond to type environments.

  As it is typical in intrinsic typing, variables are represented as
  typed (in our case sorted) DeBruijn indices \ACode{S \ACon{∋} s}, i.e.\
  values of the usual proof-relevant list-membership relation:
  \LibCode\KVariables

  Note that there is no straightforward way to construct a
  multi-sorted syntax with intrinsic typing: in a direct translation,
  the type of terms \ACode{\ACon{\_⊢\_}} would be indexed by itself, which
  most proof assistants forbid to avoid breaking logical consistency.
  We conjecture that an encoding with universe codes is possible, as
  it has been done for intrinsically typed languages with dependent
  types, but those constructions come with their own drawbacks and complexity.

  % Contrary to the usual intrinsic typing, we limit the environment
  % \ACode{S} to sorts with index \ACode{\ACon{Var}}.
  % This ensures that it is impossible to construct kind variables, as
  % it is not possible to extend \ACode{S} with the sort of kinds
  % \ACode{\ACon{𝕜}}.

  \subsection{A Structure for Multi-Sorted Syntax}
  \label{sec:syntax:structure}
  The multi-sorted syntax makes it easy to define a structure for
  syntaxes of arbitrary object-languages, i.e.\ syntaxes with
  arbitrary amounts of syntactic categories and variables:
  \LibCode\KSyntax
  The first three fields record the definitions of sorts, terms, and variable introduction.
  The last field records that variable introduction
  \ACode{\AField{`\_}} is injective, which is trivially true for
  constructors. The instantiation for our System F syntax is
  straightforward:
  \AppCode\FSyntaxInst

  \section{Renamings \& Substitutions}
  \label{sec:maps}
  \subsection{Multi-Sorted Renamings \& Substitutions}
  \label{sec:maps:example}
  Working with a sort-indexed syntax allows us to define renamings and substitutions
  that replace all variables of all sorts simultaneously:

  \ExampleCode\FExampleSubRen

  A renaming \ACode{S₁ \ADef{→ᵣ} S₂} maps variables from \ACode{S₁} to
  variables from \ACode{S₂}.
  A substitution \ACode{S₁ \ADef{→ₛ} S₂} maps variables from \ACode{S₁} to
  terms with free variables from \ACode{S₂}.

  For example, the substitution, which replaces the term variable 0 with the
  identity function and the type variable 1 with the bottom type, is defined
  as followed:
  \ExampleCode\FExampleSub

  This representation has the benefit that there is no combinatory
  explosion of substitutions and renamings, e.g.\ no extra lemmas have to be
  proved between an expression-in-expression and a type-in-expression
  substitution, because both are simply substitutions.

  \subsection{The Need for Renamings}
  \label{sec:maps:renamings}
  A problem with mechanizing languages with DeBruijn-indices is that
  the operation of applying a substitution \ACode{σ} to a term
  \ACode{t} cannot be defined directly by structural recursion on
  \ACode{t}.
  If \ACode{t} is a term like \ACode{\ACon{λx} e},
  where the subterm \ACode{e} is under a binder, then the variables
  in \ACode{e} are shifted, i.e.\ the variable \ACode{\ACon{zero}} refers
  to the variable from the binder, whereas a variable \ACode{\ACon{suc} x}
  refers to the variable \ACode{x} from outside of the binder.
  As the terms contained in \ACode{σ} may themselves contain free variables,
  they need to be shifted, too, before they can be substituted
  for variables in \ACode{e}. 
  Shifting the variables in a term is itself a substitution, which maps
  each variable \ACode{x} to the term \ACode{\ACon{`} (\ACon{suc} x)}.
  However, applying this shifting substitution to the terms in
  \ACode{σ} is not structurally recursive, as the terms in \ACode{σ}
  are not subterms of \ACode{\ACon{λx} e}.

  The usual workaround is to first define renamings,
  i.e.\ substitutions that replace variables with variables.
  In contrast to general substitutions, renamings can be easily
  shifted: they only contain variables \ACode{x}, which can be
  shifted by simply taking their successor \ACode{\ACon{suc} x}.
  As the shifting substitution is a renaming, we can then define substitution,
  where we apply the shifting \emph{renaming} to the terms in \ACode{σ} when
  the substitution needs to go under a binder.

  % The usual workaround is to define renamings first and use them
  % to weaken the terms in substitutions when going under binders.
  While this keeps lemmas simple (requiring only structural induction),
  it duplicates the amount of work as all operations and lemmas have
  to be defined and proved for both renamings and substitutions.

  \subsection{Unifying Renamings \& Substitutions}
  \label{sec:maps:kits}
  To avoid the duplication between renamings and substitutions,
  McBride\cite{DBLP:journals/jar/BentonHKM12, unpublished:mcbride2005kits}
  introduced an abstraction called \emph{kits}.\footnote{
    While kits were originally formulated for intrinsically-typed languages,
    they nicely extend to our extrinsically-typed multi-sorted syntax, whose
    sort-indexing is a form of intrinsic typing.
  }

  % A \ACode{Kit} is a structure that captures the commonalities
  % between variables and terms:
  A \ACode{Kit} is a structure that allows to abstract over whether
  something is a term or a variable. The intention is to instanciate
  this structure exactly twice (once for variables and once for terms),
  and then write definitions, which are parameterized over a kit and
  consequently can be used for both variables and terms.
  \LibCode\KKit

  As we intend to have exactly two \ACode{\ACon{Kit}} instances, we choose names of
  the form \ACode{x/y}, where \ACode{x} is the name we choose for the
  variable instance, and \ACode{y} is the name we choose for the term
  instance.
  For example the parameter type \ACode{\_∋/⊢\_} will be instanciated
  to \ACode{\ACon{\_∋\_}} for the variable kit, and to \ACode{\AField{\_⊢\_}} for the
  term kit.

  A kit provides the following operations:
  \begin{itemize}
  \item 
    \ACode{\AField{id/`}} converts a variable \ACode{S \ACon{∋} s} into a
    \ACode{S \AField{∋/⊢} s}. For the variable kit, \ACode{S ∋/⊢ s} is instanciated to \ACode{S \ACon{∋} s}, so this
    operation is the identity. For the term kit, \ACode{S ∋/⊢ s} is
    instanciated to \ACode{S \AField{⊢} s}, so this operation is the
    variable constructor \ACode{\AField{`\_}}.
  \item 
    \ACode{\AField{`/id}} converts a \ACode{S ∋/⊢ s} into a term \ACode{S \AField{⊢} s}
    and is dual to the \ACode{\AField{id/`}} operation.
  \item 
    \ACode{\AField{wk}} shifts the DeBruin-Indices in a \ACode{S ∋/⊢ s}.
    The new, unused variable \ACode{\ACon{zero}} can assume any sort \ACode{s'}.
    For variables, \ACode{\AField{wk}} is the successor \ACode{\ACon{suc}}.
    For terms, \ACode{\AField{wk}} means applying a shifting renaming to the term.
  \end{itemize}

  The operations need to satisfy the following properties:
  \begin{itemize}
  \item \ACode{\AField{`/`-is-`}} states that converting a variable first to a ``variable-or-term'' and
    then further to a term is the same as converting it directly to a
    term using the variable constructor \ACode{\AField{`\_}}.
  \item \ACode{\AField{`/id-injective}} and \ACode{\AField{id/`-injective}} state that
    \ACode{\AField{`/id}} and \ACode{\AField{id/`}} are injective. This property
    follows easily, as both the identity function and the variable
    constructor are injective.
  \item \ACode{\AField{wk-id/`}} characterizes the behaviour of the \ACode{\AField{wk}} function.
    Injecting a variable and then shifting it, is the same as injecting a shifted variable.
  \end{itemize}

  Building on the operations and axioms, we derive further operations:\footnote{
    The definitions are included directly in the record module of the
    Kit, so they are implicitly parameterized over a kit.
  }
  \begin{itemize}
  \item 
    We unify the definition of renamings \ACode{S₁ \ADef{→ᵣ} S₂} and
    substitutions \ACode{S₁ \ADef{→ₛ} S₂}, which differ only in whether they
    return variables or terms:
    \LibCode\KMap
    We call a value of type \ACode{S₁ \ADef{→ₖ} S₂} a \emph{map} and
    use the meta-variable \ACode{ϕ} for it.
  \item 
    A map can be applied to a variable:
    \LibCode\KAp
  \item 
    A map can be extended by a new variable or term:
    \LibCode\KExt
  \item 
    A map can be shifted, as the Kit provides the necessary \ACode{\AField{wk}} operation:
    \LibCode\KWkm
  \item 
    A map can be lifted, which is the operation necessary to
    move a map under a binder of sort \ACode{s}:
    \LibCode\KLift
  \item 
    There is an identity map:
    \LibCode\KId
  \item 
    There is a singleton map, which replaces \ACode{\ACon{zero}} and decreases
    all other variables by one:
    \LibCode\KSingle
  \item 
    There is a map which is equivalent to \ACode{\AField{wk}} on terms:
    \LibCode\KWeaken
  \item
    Maps have an extensional equality:
    \LibCode\KEq
  \item
    For simplicity we postulate functional extensionality:\footnote{
      The actual implementation does \emph{not} use any postulates.
      Appendix TODO explains the workaround.
    }
    \LibCode\KFunExt
  \item
    Lifting the identity map is a (larger) identity map:
    \LibCode\KIdLift
    % \LibCode\KIdLiftProof
  \end{itemize}

  We also specify notation, which makes it less cumbersome
  to explicitly pass a particular Kit to those definitions:
  \begin{itemize}
  \item \ACode{S \ADef{∋/⊢[} K \ADef{]} s} is \ACode{S ∋/⊢ s} for some \ACode{\ACon{Kit}} \ACode{K}; and
  \item \ACode{S \ADef{–[} K \ADef{]→} s} is \ACode{S \ADef{→ₖ} s} for some \ACode{\ACon{Kit}} \ACode{K}.
  \end{itemize}

  The operation of applying a map to a term depends on the concrete
  structure of a term, so we define a structure for it:
  \LibCode\KTraversal
  The fields of this structure are:
  \begin{itemize}
  \item
    \ACode{t \AField{⋯} ϕ} applies the map \ACode{ϕ} (a renaming or
    substitution) to the term \ACode{t}.
  \item
    \ACode{\AField{⋯-var}} states that applying a map \ACode{ϕ} to a variable
    term \ACode{\AField{`} x}, is the same as applying \ACode{ϕ} to
    the variable \ACode{x}, and then converting the result from \ACode{S₂ ∋/⊢ S}
    to \ACode{S₂ ⊢ S} via \ACode{\AField{id/`}}.
  \item
    \ACode{\AField{⋯-id}} states that applying the identity map
    \ACode{id} to a term does not change the term.
  \end{itemize}

  Finally, we define the actual kit instances.
  The variable kit definition is straightforward:
  \LibCode\KKitVar

  The term kit requires both the variable kit and the
  \ACode{\ACon{Traversal}} to be defined, because shifting a term with \ACode{\AField{wk}}
  means applying the shifting renaming to the term.
  Hence, we define the term kit in the record module of \ACode{\ACon{Traversal}}:
  \LibCode\KKitTerm

  % The only task left now is to create the two instances for the kits
  % and define how a map can be applied to a term.
  % While the variable kit can be defined as expected, the term kit
  % raises a dependency problem: The \ACode{\AField{wk}} operation for terms requires us
  % to already know how to apply a renaming to term.
  % To solve this problem, McBride came up with a clever solution:
  % Applying a map to a term, can be defined without even having any Kit-instances yet.
  % Afterwards we can first define the variable kit, and in the
  % definition of the term kit, we are then already allowed to apply renamings.
  % After the definition of the term-kit we are then allowed to apply
  % both renamings and substitutions as both kits defined.

  Note that all definitions so far are library code. To make them
  available for our System F example, all we need to do is
  to create an instance of \ACode{\ACon{Traversal}}.

  We start with the operation of applying a map to a term:
  \AppCode\FTraversalOp
  The interesting cases are those with variables and binders:
  \begin{itemize}
  \item 
    In the variable case \ACode{(\ACon{`} x) \ADef{⋯} ϕ}, we first apply the map
    \ACode{ϕ} to the variable \ACode{x}. If \ACode{ϕ} is a renaming,
    we get back a variable and need to apply the variable constructor
    \ACode{\ACon{`\_}} to it. If \ACode{ϕ} is a substitution,
    we get back a term that we can use directly.
    Hence, the use of \ACode{`/id}.
  \item 
    In cases where the operation needs to go under a binder, like
    \ACode{(\ACon{λx} e) \ADef{⋯} ϕ}, we lift the map using \AField{\_↑\_} before
    we apply it to the subterm to account for the bound variable.
  \end{itemize}


  \AppCode\FTraversalId
  \AppCode\FTraversalIdProofInteresting
  % \LibCode\FTraversalIdProofRest
  \AppCode\FTraversal
  
  \ExampleCode\FExampleTrav



  % \subsection{Unused}
  % \LibCode\KKitOpenInst
  % \LibCode\KKitOpen

  \section{Map Composition}
  \label{sec:composition}

  % - Reason about multiple applications in terms of a single application
  % - e.g. wk-cancels-⦅⦆ or dist-↑-⦅⦆, often important for induction hypothesis
  % - Mcbride uses tactics
  % - We introduce an abstraction similar to kits
  % - ComposeKit has primitives for composition, ComposeTraversal has the property

  %%%%%%%%%%

  In this section, we extend our framework with a single composition
  operator for arbitrary maps.

  Composition \AField{\_·ₖ\_} equips our framework with the power to
  reason about multiple maps \ACode{ϕ₁} and \ACode{ϕ₂} being applied
  to a term in sequence, in terms of a single application:

  The core property of composition is that applying two maps
  \ACode{ϕ₁} and \ACode{ϕ₂} in sequence to a term \ACode{t}, is the same
  as applying their composition \ACode{(ϕ₁ \AField{·ₖ} ϕ₂)} to \ACode{t}, i.e.
  $$
  \ACode{(t \AField{⋯} ϕ₁) \AField{⋯} ϕ₂ \ACon{≡} t \AField{⋯} (ϕ₁ \AField{·ₖ} ϕ₂)}.
  $$

  %%%%%%%%%%

  In this section, we extend our framework with a single composition
  operator for arbitrary maps.

  Composition \AField{\_·ₖ\_} equips our framework with the power to
  reason about multiple maps \ACode{ϕ₁} and \ACode{ϕ₂} being applied
  to a term in sequence:

  \ACode{\AField{⋯-assoc} t ϕ₁ ϕ₂} \ \ : \ \ \ACode{(t \AField{⋯} ϕ₁) \AField{⋯} ϕ₂ \ACon{≡} t \AField{⋯} (ϕ₁ \AField{·ₖ} ϕ₂)}

  For many lemmas, e.g. substitution-preserves-typing in System F,
  it is necessary to apply an equality like \ACode{t ⋯ σ₁ ⋯ σ₂ ≡ t ⋯ σ₂' ⋯ σ₁'}
  where the induction hypothesis requires \ACode{t' ⋯ σ₁'}.

  %%%%%%%%%%

  In this section, we extend our framework with a single composition
  operator for arbitrary maps.

  Composition of substitutions is important for most language
  formalizations, as it allows to reason about the meaning of applying
  multiple substitutions to a term. This appears for example in the proof of
  substitution-preserves-typing for System F, where in the
  case of type-application \ACode{(e \ACon{∙} t) \ADef{⋯} σ} we need to reason about
  \ACode{(e \ADef{⋯} \ADef{⦅} t \ADef{⦆}) \ADef{⋯} σ}, which is equivalent to
  \ACode{e \ADef{⋯} (\ADef{⦅} t \ADef{⦆} \ADef{·ₖ} σ)},
  where \ACode{\_\ADef{·ₖ}\_} is backward composition.

  As we defined substitution in terms of renamings, we need to
  consider all four compositions between renamings and substitutions.
  While the composition operations are defined independently of each other,
  the \ACode{\AField{⋯-assoc}} lemma for two substitutions, depends on the
  \ACode{\AField{⋯-assoc}} lemmas between a renaming and a substitution, which in
  turn depend on the \ACode{\AField{⋯-assoc}} lemma between two renamings.

  McBride et al.\cite{DBLP:journals/jar/BentonHKM12} addressed this
  issue by duplicating the definitions and using tactics to reduce
  boilerplate in proofs.

  In contrast we define structures similar to \ACode{\ACon{Kit}} and
  \ACode{\ACon{Traversal}}, which allows us to abstract over all four
  compositions and use the same trick as before to eliminate the
  dependencies.
  This has the benefit that a user of our library has to write less
  boilerplate, but more importantly it allows to prove lemmas about the
  composition of arbitrary maps, which enable us later to unify type
  preservation of all substitution and renaming operations into a single
  lemma.

  \subsection{An Examination of Composition}
  \label{sec:composition:example}
  To motivate our abstraction for composition, we first look
  at the four compositions individually:
  \ExampleCode\KExFourComps
  The definitions reveal two interesting properties:
  \begin{enumerate}
  \item
    If we compose two maps \ACode{ϕ₁} and \ACode{ϕ₂}, then the
    resulting map is a renaming, iff both \ACode{ϕ₁} and \ACode{ϕ₂} are
    renamings.
    In other words, 
    if \ACode{ϕ₁} is a \ACode{K₁}-map and \ACode{ϕ₂} is a \ACode{K₂}-map,
    then the result is a \ACode{(K₁ ⊔ K₂)}-map, where \ACode{⊔} refers to the
    lattice for \ACode{\{ \ADef{Kᵣ} , \ADef{Kₛ} \}}
    generated by \ACode{\ADef{Kᵣ} $\leq$ \ADef{Kₛ}}.
  \item
    All four compositions first apply \ACode{ϕ₁} to \ACode{x},
    and then apply \ACode{ϕ₂} to the result.
    If \ACode{ϕ₁} is a renaming, this result is another variable, but
    if \ACode{ϕ₁} is a substitution, this result is a term.
  \end{enumerate}
  With the \ACode{\ACon{Kit}} abstraction, we can easily abstract over
  \ACode{ϕ₂} being a renaming or a substitution:
  \ExampleCode\KExTwoComps

  But to abstract over \ACode{ϕ₁}, the \ACode{\ACon{Kit}} abstraction
  is not sufficient: while it allows us to abstract over what we are applying, i.e.
  a renaming or a substitution, it does not allow us to
  abstract over what we are applying it to, i.e. a variable or a term.
  For the latter we have two distinct operations \ACode{\ADef{\_\&\_}}
  and \ACode{\ADef{\_⋯\_}}.

  To fill this gap, we introduce a new abstraction that we call a
  \ACode{\ACon{ComposeKit}},
  which provides an operation \ACode{\AField{\_\&/⋯\_}} that unifies
  \ACode{\ADef{\_\&\_}} and \ACode{\ADef{\_⋯\_}}, allowing us
  to define a general composition in the spirit of:
  \ExampleCode\KComposition

  \ACode{\ACon{ComposeKit}} and \ACode{\ADef{\_·ₖ\_}} are analogous to
  \ACode{\ACon{Kit}} and \ACode{\ADef{\_→ₖ\_}}, whereas
  \ACode{\ACon{ComposeTraversal}} and \ACode{\AField{⋯-assoc}} are analogous to
  \ACode{\ACon{ComposeTraversal}} and \ACode{\AField{\_⋯\_}}.
  

  
  \subsection{WkKits}
  \label{sec:composition:wkkit}

  In the definition of \ACode{\ACon{Kit}} we required the axiom
  \ACode{\AField{wk-id/`}}, which captured the interaction between
  \ACode{\AField{wk}} and \ACode{\AField{id/`}}:
  \ExampleCode{\KWkId}
  Injecting a variable with \ACode{\AField{id/`}} and then shifting it,
  is the same as injecting a shifted variable.

  Now that we have defined the \ACode{\ACon{Traversal}} structure, we
  can formulate a similar interaction between
  \ACode{\AField{wk}} and \ACode{\AField{`/id}}:
  \ExampleCode{\KIdWk}
  Shifting a variable/term \ACode{x/t} with \ACode{\AField{wk}} and then injecting
  it to a term, is the same as injecting \ACode{x/t} to a term and then applying
  a shifting renaming.
  

  As this lemma depends on map application \ACode{\ADef{\_⋯\_}} being
  already defined, we cannot add it to the original \ACode{\ACon{Kit}}
  structure, but need to define a new structure for it, which we call
  a \ACode{\ACon{WkKit}}:
  \LibCode\KWkKit

  We then create exactly two instances of the \ACode{\ACon{WkKit}} for
  the variable and term kit, respectively. 
  \LibCode\KWkKitInstances

  Both the structure and the instances are part of the library and do
  not require application code.

  \subsection{Composition}
  \label{sec:composition:ckit}

  Using the \ACode{\ACon{WkKit}}, we then define
  the \ACode{\ACon{ComposeKit}} and \ACode{\ACon{ComposeTraversal}}
  structures, which serve analogous purposes to \ACode{\ACon{Kit}}
  and \ACode{\ACon{Traversal}} from before:
  the library provides a \ACode{\ACon{ComposeKit}} for each of the
  four compositions, whereas the \ACode{\ACon{ComposeTraversal}}
  structure needs to be instanciated by the application with
  lemmas parameterized over arbitrary \ACode{\ACon{ComposeKit}}s.
  This gives the user a composition operation
  \ACode{\AField{\_·ₖ\_}} between arbitrary maps and corresponding
  lemmas, instead of multiple definitions and lemmas about concrete
  maps, enabling us to reason on a more abstract level and to avoid
  further boilerplate.



  \LibCode\KComposeKit
  \LibCode\KComposition
  \LibCode\KComposeKitAp
  % \LibCode\KComposeKitApProof
  \LibCode\KDistLiftCompose
  % \LibCode\KDistLiftComposeProof
  \LibCode\KComposeKitNotation
  \LibCode\KComposeTraversal
  \LibCode\KCommLiftWeaken
  % \LibCode\KCommLiftWeakenProof
  \LibCode\KCommLiftWeakenTraverse
  % \LibCode\KCommLiftWeakenTraverseProof
  \LibCode\KComposeKitInstances
  \LibCode\KComposeKitInstancesConcrete
  \LibCode\KWeakenCancelsSingle
  % \LibCode\KWeakenCancelsSingleProof
  \LibCode\KWeakenCancelsSingleTraverse
  % \LibCode\KWeakenCancelsSingleTraverseProof
  \LibCode\KDistLiftSingle
  % \LibCode\KDistLiftSingleProof
  \LibCode\KDistLiftSingleTraverse
  % \LibCode\KDistLiftSingleTraverseProof

  \subsection{System F}
  \AppCode\FAssoc
  \AppCode\FAssocProofInteresting
  % \AppCode\FAssocProofRest
  \AppCode\FComposeTraversal

  \section{Types \& Contexts}
  \label{sec:types}
  % To define typing contexts and a typing relation, we need to know
  % which sorts of terms play the role of types for other sorts of terms.
  % When modeling a typed language with multi-sorted syntax, both terms
  % and types are represented as terms, but with different sorts.
  % To define typing contexts and a typing relation, we need to record for each term
  % from 
  % describe terms, and ocan be mapped to 
  % In a typed language,

  In the context of multi-sorted syntax, the notation of a type can be
  described as a mapping between sorts.
  For System F, the expression sort \ACode{\ACon{𝕖}} maps to the type sort
  \ACode{\ACon{𝕥}} and the sort \ACode{\ACon{𝕥}} maps to the kind sort
  \ACode{\ACon{𝕜}}.
  To teach our framework about types, we have to instantiate the following structure:
  \LibCode\KTypeSorts
  For System F the instanciation is
  \AppCode\FTypes
  For a nicer interface, we define a type analogously to a term:
  \LibCode\KTypes

  \subsection{Typing Context}
  A typing context is then a function which maps variables to types.
  As we want our framework to support dependent types, the types returned by
  a typing context are allowed to use the domain of the 
  To be able to deal with dependent types, the result types are only allowed
  to refer to the variables that come before 
  \LibCode\KContextHelper
  \LibCode\KContexts
  \LibCode\KContextLookup

  \LibCode\KVariableTyping

  \section{Typing}
  \label{sec:typing}
  Equipped with a notion of types and type context we are ready to define
  the multi-sorted typing relation for System F, incorporating both
  typing and kinding:
  \AppCode\FTyping
  The interesting cases are:
  \begin{itemize}
  \item
    the variable typing constructor covers both expression- and
    type-variables, analogously to the variable term constructor;
  \item
    the typing of the lambda abstraction \ACode{\ACon{⊢λ}} weakens the
    type of the codomain \ACode{t₂}.
    This is necessary, because with multi-sorted syntax, types could
    also depend on expressions, so the sub typing derivation accounts for
    another variable which is not used by the type.
  \item
    the kinding constructor \ACode{\ACon{⊢τ}} states that all types
    have kind \ACode{\ACon{★}}. This is sufficient for System F as types
    are automatically well-scoped due to intrinsic scoping.
  \end{itemize}
  To teach the framework about typing, we create a structure analogously to
  \ACode{\ACon{Syntax}}:
  \LibCode\KTyping
  and instanciate it for System F:
  \AppCode\FTypingInst

  Next we define \ACode{\ACon{TypingKit}}s, which are analog to
  \ACode{\ACon{Kit}}s, but abstract about variable and term
  \emph{typing}, instead of variables and terms, themselves.
  \LibCode\KTypingKit
  Building on the fields of a \ACode{\ACon{TypingKit}}, we define further operations:
  \begin{itemize}
  \item
    Using the variable/term typing, we can define a renaming/substitution typing:
    \LibCode\KMapTyping
  \item 
    Lifting a map preserves its typing:
    \LibCode\KLiftTyping
    % \LibCode\KLiftTypingProof
  \item 
    If a variable/term has a typing, then so does its singleton renaming/substitution:
    \LibCode\KSingleTyping
    % \LibCode\KSingleTypingProof
  \end{itemize}
  To make it easier to explicitly pass typing kits,
  we define the notation \ACode{Γ₂ \ADef{∋*/⊢*[} TK \ADef{]} ϕ \ADef{∶} Γ₁}
  to stand for \ACode{Γ₂ \ADef{∋*/⊢*} ϕ \ADef{∶} Γ₁} given some
  \ACode{\ACon{TypingKit}} \ACode{TK}.
  % \LibCode\KTypingNotation

  We then define a \ACode{\ACon{TypingTraversal}} analogously to
  \ACode{\ACon{Traversal}}, but instead of defining the application of
  maps, it defines the type preservation of applying maps:
  \LibCode\KTypingTraversal
  Given a variable/term \ACode{e} with typing \ACode{⊢e} and
  a renaming/substitution \ACode{ϕ} with typing \ACode{⊢ϕ},
  the term \ACode{⊢e \AField{⊢⋯} ⊢ϕ} is a typing for \ACode{e \AField{⋯} ϕ}.

  Given a \ACode{\ACon{TypingTraversal}}, we can easily instanciate the
  \ACode{\ACon{TypingKits}} for variables and terms:
  \LibCode\KTypingInstances
  % \LibCode\KTypingTraversalNotation

  We are then ready to create a \ACode{\ACon{TypingTraversal}}
  instance for System F:
  \AppCode\FPreserve
  \AppCode\FTypingTraversal

  As the \ACode{\ACon{Traversal}} and  \ACode{\ACon{ComposeTraversal}} instances
  can be generally derived via reflection,
  the \ACode{\AField{\_⊢⋯\_}} lemma is in fact the only lemma that
  has to been proved manually for subject reduction.
  From this single lemma follows type preservation for all operations
  of both renamings and substitutions for all sorts of variables
  simultaneously.

  \section{Semantics}
  \label{sec:semantics}
  We define a standard small-step operational semantics for System F
  with full reduction:
  \AppCode\FReduction

  \section{Subject Reduction}
  \label{sec:subjectreduction}
  Proving subject reduction is now straightforward:
  \AppCode\FSubjectReduction
  \AppCode\FSubjectReductionProofInteresting
  We only listed the cases that do not follow directly from the
  induction hypothesis:
  \begin{itemize}
  \item The beta-reduction rule for type-application, \ACode{\ACon{β-Λ}},
    is a direct consequence of substitution preserves typing.
    \ACode{⊢e₂} is the typing for \ACode{e₂}.
    \ACode{⊢⦅ ⊢e₂ ⦆} is the substitution-typing for the singleton substitution 
    \ACode{\AField{⦅ e₂ ⦆}}.
    \ACode{\AField{⊢e₁ ⊢⋯ ⊢⦅ ⊢e₂ ⦆}} states that applying the singleton substitution
    to \ACode{e₁} preserves typing.
  \item The beta-reduction rule for value-application is almost the same,
    but requires us to addionaly apply an equality to the type index.
  \end{itemize}

  % \FSubjectReductionProofRest

  \section{Reflection \& Generics}
  \label{sec:reflection}
  We used Agda's reflection mechanism\cite{TODO} to derive
  instanciations related to all structures for untyped substitition,
  i.e. \ACode{\ACon{Traversal}} and \ACode{\ACon{ComposeTraversal}}.

  To gain insight into the class of object languages supported by our
  reflection algorithm, we modeled a class of object languages using a
  generic programming technique and instanciated the structures
  generically. The class contains all object languages which:
  \begin{enumerate}
  \item Have a variable constructor of type TODO;
  \item Uses subterms only directly (e.g. not in lists);
  \item Subterms only extend the scope-context.
  \end{enumerate}

  Our reflection algorithm derives proofs with exactly the same
  structure as the generic proof, giving high confidence that it covers
  the same class of languages.

  The formal definition of the generic class can be found in
  Appendix~\ref{sec:generic-class} and the actual implementation.

  We were able to describe many languages in this shape, including
  session types and type state.

  We believe restriction 2 is purely technically and can be lifted
  with a more sophisticated reflection algorithm, as parameterized
  datastructures can also be inlined into the syntax definition as terms
  of a new sort.

  We believe restriction 3 can be lifted partially to allow for
  example the encoding of linear types that requires context
  splitting. This has already be done for intrinsical kits\cite{TODO}.


  \section{Case Studies}
  \label{sec:casestudies}
  \begin{itemize}
  \item
    For lambda calculus with dependent function types, the framework
    just works out of the box for both deriving and instanciating the
    \ACode{\ACon{TypingTraversal}}. Additionally, having the
    \ACode{\ACon{ComposeKit}} abstraction turned out to be useful
    to prove confluence, allowing to unify certain lemmas, which
    otherwise need to be proved for both renamings and substitutions,
    e.g. that for two terms \ACode{t} and \ACode{t'}
    with \ACode{t \ACon{↪} t'} it follows that \ACode{(t \AField{⋯} ϕ)
    \ACon{↪} (t' \AField{⋯} ϕ)} for any map \ACode{ϕ}.
  \item
    For System F with subtyping the main challenges are how to represent
    subtyping constraints and how to deal with the fact that
    substitution preserves typing is not generally true, as type variables
    have subtyping bounds that need to be respected.
    Instead of defining typing contexts and type preservation lemmas independent
    of our framework, we found a way that still allows us to benefit
    from the typing machinery.
    When binding a type variable with a subtyping constraint \ACode{α <: t},
    we first bind the type variable as \ACode{α : ★}, and then bind the constraint
    with a dummy name \ACode{\_ ∶ (α <: t)}. This description is
    similar to first-class constraints, but restricted enough to be
    isomorphic to the original formalization.
    With that encoding substitution preserves typing is generally true again, enabling
    the use of the framework's typing contexts and \ACode{\ACon{TypingKit}} machinery.
    Replacing a type variable \ACode{α <: t} with a type \ACode{t'}
    which is not a subtype of \ACode{t'}, the resulting term is still
    well-typed, but in a context with an insatisfiable constraint.
  \item
    Object language with pattern matching pose an interesting problem.
    A clause \ACode{p ⇒ e} in a match-expression consists of a pattern
    \ACode{p} and a continuation expression \ACode{e}.
    The pattern \ACode{p} can bind arbitrary many variables in subpatterns,
    which are then available as free variables in \ACode{e}.
    % The challenge is to track the sorts of variables bound by a pattern,
    % to make them available to \ACode{e} by extending \ACode{e}'s sort
    % context correspondingly.
    To track the sorts of variables bound by a pattern, one can define
    the sort of patterns to contain the sorts of the variables that it binds:
    % 𝕡 : List (Sort Var) → Sort NoVar
    The syntax for variable patterns and clauses can then be specified as:
    % varpat : S ⊢ 𝕡 [ 𝕖 ]  -- pattern binding an expression variable
    % pairpat : S ⊢ 𝕡 S₁ → S ⊢ 𝕡 S₂ → S ⊢ 𝕡 (S₁ ++ S₂)
    % clause : S ⊢ 𝕡 S' → (S' ++ S) ⊢ 𝕖 → S ⊢ 𝕔
  \end{itemize}

  \section{Related Work}
  \label{sec:related}

  The kit abstraction for unifying renamings and substitutions
  appeared first in an unpublished manuscript by
  McBride\cite{unpublished:mcbride2005kits}, and then later in
  Benton et al.\cite{DBLP:journals/jar/BentonHKM12}. 
  Wood and Atkey\cite{DBLP:journals/corr/abs-2005-02247} propose an
  extension to kits that supports substructural types via resource
  vectors.
  In all three cases they are formulated for intrinsic typing.

  \emph{Autosubst}\cite{DBLP:conf/itp/SchaferTS15}
  is a Coq framework, which derives parallel substitution definitions and
  lemmas for languages from annotated Coq syntax definitions using
  extrinsic typing, extrinsic scoping, and de Bruijn indices.
  The framework is implemented in Coq's tactic language LTAC and comes
  with a decision procedure for all assumption-free, equational
  substitution-lemmas.
  The implementation of Autosubst deals with multiple variable sorts
  by generating multiple substitutions and corresponding interaction lemmas.
  Autosubst does not provide any machinery for type preservation and
  does not unify renaming and substitution.

  \emph{Autosubst 2}\cite{DBLP:conf/cpp/StarkSK19} is a standalone
  code generator, which translates second-order HOAS specifications into
  mutual inductive term sorts. Compared to Autosubst 1, it features
  mutually recursive object languages, intrinsically scoping, and
  vectorized substitutions.
  They also define and prove lemmas for all four compositions.
  The generated syntax consists of multiple term types, indexed by
  different amounts of free variables as shown in Section~\ref{sec:syntax}.

  Allais et al.\cite{DBLP:conf/cpp/Allais0MM17} propose a powerful
  abstraction for denotational semantics and semantic fusion lemmas.
  In later work\cite{DBLP:journals/pacmpl/AllaisA0MM18}, they use
  generic programming to instanciate this abstraction for a class of
  object languages comparable to ours.
  They demonstrate how both renamings and substitutions can be
  described as semantics and how the four composition lemmas follow from
  their generic fusion lemma.
  They do cover an abstraction to unify renamings and substitutions.
  They do not show how to work with multiple variable sorts, how to
  abstract over the compositions, and how to abstract over typing in
  an extrinsically typed scenario.
  However, we believe that their framework is general enough such that
  our concepts can also be transferred to their framework.

  Abstract binding trees

  \section{Future Work}
  \label{sec:future}
  \begin{itemize}
  \item
    Enabling more object languages by allowing subterms with less
    restrictions on the form of \ACode{S}, allowing recursive
    occurences in container types like lists and finite functions, and
    adding support for substructural types as in
    \cite{DBLP:journals/corr/abs-2005-02247}.
  \item
    Extending the class of typing relations covered by
    the \ACode{\ACon{TypingTraversal}} abstraction and identifying
    a subclass for which it can be derived.
  \item
    Incorporating a decision procedure for equational
    substitution-lemmas based on $\sigma$-calculus as in Autosubst
    \cite{DBLP:conf/itp/SchaferTS15, DBLP:conf/cpp/StarkSK19}.
  \item
    Developing abstractions and derived lemmas beyond substition and
    type preservation, e.g. for confluence or denotational semantics
    as in \cite{DBLP:journals/pacmpl/AllaisA0MM18}.
  \end{itemize}

  \section{Conclusion}
  \label{sec:conclusion}

  % \bibliographystyle{ACM-Reference-Format}
  \bibliography{paper}

  \clearpage
  \appendix
  \onecolumn

  \section{Omitted Proofs}
  \label{sec:proofs}

  \subsection{Proofs for Section~\ref{sec:maps}}
  \LibCode\KIdLift
  \LibCode\KIdLiftProof

  % \AppCode\FTraversalId
  % \AppCode\FTraversalIdProofInteresting
  % \LibCode\FTraversalIdProofRest

  \subsection{Proofs for Section~\ref{sec:composition}}
  \LibCode\KComposeKitAp
  \LibCode\KComposeKitApProof

  \LibCode\KDistLiftCompose
  \LibCode\KDistLiftComposeProof

  \LibCode\KCommLiftWeaken
  \LibCode\KCommLiftWeakenProof

  \LibCode\KCommLiftWeakenTraverse
  \LibCode\KCommLiftWeakenTraverseProof

  \LibCode\KWeakenCancelsSingle
  \LibCode\KWeakenCancelsSingleProof

  \LibCode\KWeakenCancelsSingleTraverse
  \LibCode\KWeakenCancelsSingleTraverseProof

  \LibCode\KDistLiftSingle
  \LibCode\KDistLiftSingleProof

  \LibCode\KDistLiftSingleTraverse
  \LibCode\KDistLiftSingleTraverseProof


  % \AppCode\FAssoc
  % \AppCode\FAssocProofInteresting
  % \AppCode\FAssocProofRest


  \subsection{Proofs for Section~\ref{sec:typing}}
  \LibCode\KLiftTyping
  \LibCode\KLiftTypingProof

  \LibCode\KSingleTyping
  \LibCode\KSingleTypingProof


  % \AppCode\FSubjectReduction
  % \AppCode\FSubjectReductionProofInteresting


  \section{Generic Class of Object Languages}
  \label{sec:generic-class}

\end{document}